print("X1:" + str(X1) + " X2:" + str(X2))
 
print("W1:" + str(W1) + " W2:" + str(W2))

print("bias: " + str(b))

print("label: " + str(y[c]))

///
import numpy as np
# Setting the random seed, feel free to change it and see different solutions.
np.random.seed(42)

def stepFunction(t):
    if t >= 0:
        return 1
    return 0

def prediction(X, W, b):
    return stepFunction((np.matmul(X,W)+b)[0])

# TODO: Fill in the code below to implement the perceptron trick.
# The function should receive as inputs the data X, the labels y,
# the weights W (as an array), and the bias b,
# update the weights and bias W, b, according to the perceptron algorithm,
# and return W and b.
def perceptronStep(X, y, W, b, learn_rate = 0.01):
    # Fill in code
    c = 0
    for x in X:
        X1 = x[0]
        X2 = x[1]
        W1 = W[0]
        W2 = W[1]
        
        label = y[c]
        
        #calc
        score = W1*X1 + W2*X2 + b
        #print("Score: " + str(score))
        
        #check if label is correct
        update_W = []
        update_b = []
        if score >= 0 and label == 0: 
            update_W.append([W1 - X1*learn_rate, W2 - X2*learn_rate])
            update_b.append(b - learn_rate)
            
        elif score < 0 and label == 1:
            update_W.append([W1 + X1*learn_rate, W2 + X2*learn_rate])
            update_b.append(b + learn_rate)
        
        else:
            update_W.append([W1, W2])
            update_b.append(b)
            
        c += 1

        print(W)
        
        
    return update_W, update_b
    
# This function runs the perceptron algorithm repeatedly on the dataset,
# and returns a few of the boundary lines obtained in the iterations,
# for plotting purposes.
# Feel free to play with the learning rate and the num_epochs,
# and see your results plotted below.
def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 1):
    x_min, x_max = min(X.T[0]), max(X.T[0])
    y_min, y_max = min(X.T[1]), max(X.T[1])
    W = np.array(np.random.rand(2,1))
    b = np.random.rand(1)[0] + x_max
    # These are the solution lines that get plotted below.
    boundary_lines = []
    for i in range(num_epochs):
        # In each epoch, we apply the perceptron step.
        W, b = perceptronStep(X, y, W, b, learn_rate)
        boundary_lines.append((-W[0]/W[1], -b/W[1]))
    return boundary_lines




//////////////

label = y[c]
        
        #calc
        score = W1[0]*X1 + W2[0]*X2 + b
        #print("Score: " + str(score))
        
        #check if label is correct

        if score >= 0 and label == 0: 
            #update_W[c] = [W1 - X1*learn_rate, W2 - X2*learn_rate]
            #update_b.append(b - learn_rate)
            print("out")
            
        elif score < 0 and label == 1:
            #update_W[c] = [W1 + X1*learn_rate, W2 + X2*learn_rate]
            #update_b.append(b + learn_rate)
            print("in")
        else:
            update_W.append([[W1[0]][W2[0]]])
            update_b.append(b)
            
        c += 1


       #check if label is correct
       if score >= 0 and label == 0: 
            print("substract")
        elif score < 0 and label == 1:
            print("add")
        else:
            print("all good")