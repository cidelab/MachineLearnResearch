{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part I \n",
    "\n",
    "We will write code that performs logistic regression on linearly separable data, by learning weights through gradient descent of a cost function. This is a simple problem but it will allow us to understand better how a network with one hidden layer works in Part II. \n",
    "\n",
    "* The network required has an input layer of two neurons plus a bias and an output layer of one neuron. So the data matrix $\\mathbf{X}$ has dimensions $(n_s,2)$, where $n_s$ is the number of samples. The target matrix $\\mathbf{T}$, containing ones or zeros depending on the classification of the data, has dimensions $(n_s,1)$.\n",
    "* On including the bias node (set to unity) we increase the column size of the data matrix by one and call this matrix $\\mathbf{\\tilde{X}}$.\n",
    "* There is a weight matrix (just a vector in this case) $\\mathbf{w}$ that has dimensions $(3,1)$.\n",
    "* The activation function of the output neuron is a sigmoid function of its input $z$ such that $f(z)=1/(1+\\exp(-z))$ where for one data point $z=\\sum_i\\tilde{x}_iw_i$ is a linear sum of the weighted inputs.\n",
    "* The matrix of predictions of the network is therefore \n",
    "$$\\mathbf{P}=f(\\mathbf{\\tilde{X}\\mathbf{w}})$$\n",
    "* The average cost function across the data is $$C=-\\frac{1}{n_s}\\sum_s\\left[T_s\\log(P_s)+(1-T_s)\\log(1-P_s)\\right]. $$\n",
    "\n",
    "* As a general convention we will use upper-case letters when considering matricies of all data and lower-case letters for aone single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# libraries required for plotting and maths\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 Generate the data and the target\n",
    "\n",
    "* Each data point comprises two numbers, both randomly distributed between $-1$ and $1$, which can be intepreted as an $(x, y)$ coordinate on a plane.\n",
    "* If the point obeys $y>mx+\\kappa$ we assign it a target value $t=1$, if not it has $t=0$.\n",
    "* For $n_s$ samples the data can be summarised by two matricies. The first $\\mathbf{X}$ has the coordinates and dimensions $(n_s,2)$ and the second $\\mathbf{T}$ has the targets and has dimensions $(n_s,1)$.\n",
    "* Generate these matricies and plot the points in green that have $t=1$ and red that have $t=0$. Draw the dividing line given by $y=mx+\\kappa$.\n",
    "* Suggested parameters are $n_s=50$, $m=1$ and $\\kappa=0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.72595358, -0.29216749],\n",
       "        [ 0.74502685,  0.42610285],\n",
       "        [-0.12294924,  0.99012297],\n",
       "        [ 0.31876051, -0.96408882],\n",
       "        [ 0.06535822, -0.167663  ]]),\n",
       " array([-0.29216749,  0.42610285,  0.99012297, -0.96408882, -0.167663  ]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.linspace(-2,3)\n",
    "y=x**2\n",
    "ns = 5\n",
    "m = 1.0\n",
    "k = 0.1\n",
    "\n",
    "# normally-distributed random numbers\n",
    "x1 = 2.0 * (np.random.rand(ns, 2) - 0.5) #2d matrix between -1 < 1\n",
    "t = x1[:,1] > # get the second matrix component.\n",
    "\n",
    "# random numbers between 0 and 1\n",
    "#x2=np.random.rand(50,1)\n",
    "#y2=np.random.rand(50,1) + 2\n",
    "\n",
    "#plt.subplot(121)\n",
    "#plt.plot(x,y,)\n",
    "#plt.title(\"y=x^2\")\n",
    "#plt.xlabel(\"x\")\n",
    "#plt.ylabel(\"y\")\n",
    "\n",
    "# line.\n",
    "#y = m * x + k\n",
    "#plt.plot(x, y) \n",
    "\n",
    "#plt.plot(x1,y1,\"og\",x2,y2,\"or\")\n",
    "#plt.axis([-4,4,-4,4]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Write a function that calculates a prediction and cost for a given set of weights\n",
    "* We now include a bias so we define a new matrix $\\tilde{\\mathbf{X}}$ that includes a column of ones. This matrix has dimensions $(n_s,3)$.\n",
    "* The weight matrix $w$ has dimensions ($3,1)$ and stores the information learned about the data.\n",
    "* The prediction matrix $\\mathbf{P}$ has the same dimensions as $\\mathbf{T}$ and is given by $\\mathbf{P}=f(\\tilde{\\mathbf{X}}\\mathbf{w})$ where $f(z)=1/(1+e^{-z})$.\n",
    "* The cost function is $$C=-\\frac{1}{n_s}\\sum_s\\left[T_s\\log(P_s)+(1-T_s)\\log(1-P_s)\\right]$$\n",
    "* Write a function that takes $\\tilde{\\mathbf{X}}$ and a weight matrix $\\mathbf{w}$ as inputs and outputs the prediction matrix $\\mathbf{P}$ and cost $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MyTest(x, w, t):\n",
    "    pred = 1 / (1 + np.exp(z))\n",
    "    cost = -(1/len(x) + t* np.log(p) + (1 - t)\n",
    "     \n",
    "    return (pred,cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Write a function that calculates the weight gradients\n",
    "We first do a little theory to calculate the form of the cost gradient with respect to changes in the weight. For simplicity we will consider a single data point first.\n",
    "* Let the cost of one sample be\n",
    "$$c=-[t\\log(p)+(1-t)\\log(1-p)].$$ \n",
    "Show that \n",
    "$$ \\frac{dc}{dp}=\\frac{p-t}{p(1-p)},~~~\\frac{dp}{dz}=p(1-p) ~~~\\mbox{ and } \\frac{dz}{dw_i}=\\tilde{x}_i$$\n",
    "* Hence show that $$\\frac{dc}{dw_i}=\\frac{dp}{dz}\\frac{dz}{dw_i}=\\tilde{x}_i(p-t) ~~\\mbox{ and }~~\\frac{dC}{dw_i}=\\frac{1}{n_s}\\sum_s\\tilde{X}_{si}(P_{si}-T_{si}) ~~\\mbox{for the entire data set}.$$ \n",
    "* In matrix form we therefore have $$\\frac{dC}{d\\mathbf{w}}=\\frac{1}{n_s}\\tilde{X}'\\Delta^p~~~\\mbox{ where }~~~\\Delta^p=\\mathbf{P}-\\mathbf{T} ~~~\\mbox{ or }~~~\\delta^p=p-t~~~\\mbox{for one data point}$$ \n",
    "* Write a function that takes in $\\mathbf{\\tilde{X}}$, $\\mathbf{w}$, $\\mathbf{P}$ and $\\mathbf{T}$ and outputs $dC/d\\mathbf{w}$ as a matrix  of dimension $(1,3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 Gradient descent for the weights\n",
    "* Write a loop that does $n_i$ gradient-descent iterations, where for each one the weight matrix is updated using the rule $$ \\mathbf{w}_\\mathrm{new}=\\mathbf{w}_\\mathrm{old}-\\alpha\\frac{dC}{d\\mathbf{w}} $$ where $\\alpha$ is a positive learning rate that you can choose.\n",
    "* Plot a graph of the cost $C$ as a function of the iteration steps and check that it is monotonically decreasing.\n",
    "* When the input $z$ into the output node vanishes then $p=0.5$ which defines the separation line. The criterion $z=0$ corresponds to $xw_1+yw_2+w_3=0$ and defines a line separating the classification in the $x-y$ plane. Plot the line for your weights on the graph of data points and compare it to the true separting line used to generate the data labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
