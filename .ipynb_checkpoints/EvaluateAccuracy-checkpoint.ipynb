{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# In this and the following exercises, you'll be adding train test splits to the data\n",
    "# to see how it changes the performance of each classifier\n",
    "#\n",
    "# The code provided will load the Titanic dataset like you did in project 0, then train\n",
    "# a decision tree (the method you used in your project) and a Bayesian classifier (as\n",
    "# discussed in the introduction videos). You don't need to worry about how these work for\n",
    "# now\n",
    "#\n",
    "# What you do need to do is import a train/test split, train the classifiers on the\n",
    "# training data, and store the resulting accuracy scores in the dictionary provided.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "# Limit to numeric data\n",
    "X = X._get_numeric_data()\n",
    "# Separate the labels\n",
    "y = X['Survived']\n",
    "# Remove labels from the inputs, and age due to missing data\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree has accuracy:  0.659176029963\n",
      "GaussianNB has accuracy:  0.677890011223\n"
     ]
    }
   ],
   "source": [
    "# The decision tree classifier\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(xTest,yTest)\n",
    "print \"Decision Tree has accuracy: \",accuracy_score(yTrain, clf1.predict(xTrain))\n",
    "\n",
    "# The naive Bayes classifier\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X,y)\n",
    "print \"GaussianNB has accuracy: \",accuracy_score(y, clf2.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
