{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Faces recognition example\n",
      "\n",
      "The dataset used in this example is a preprocessed excerpt of the\n",
      "\"Labeled Faces in the Wild\", aka LFW_:\n",
      "http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
      ".. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
      "original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Faces recognition example\n",
    "\n",
    "The dataset used in this example is a preprocessed excerpt of the\n",
    "\"Labeled Faces in the Wild\", aka LFW_:\n",
    "http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
    ".. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
    "original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
    "\"\"\"\n",
    "\n",
    "print __doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Carlos\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import logging\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-17 23:09:22,595 Loading LFW people faces from C:\\Users\\Carlos\\scikit_learn_data\\lfw_home\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_Classes: 7\n"
     ]
    }
   ],
   "source": [
    "#download the data and load it as numpy arrays.\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "#introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "np.random.seed(42)\n",
    "\n",
    "# for machine learning we use the data directly \n",
    "# (as relative pixel position info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# The label to predict is the ide of the person.\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_Classes = target_names.shape[0]\n",
    "\n",
    "print\"Total dataset size\"\n",
    "print \"n_samples: %d\" % n_samples\n",
    "print \"n_features: %d\" % n_features\n",
    "print \"n_Classes: %d\" % n_Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into a training and testing set\n",
    "X_train, X_Test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.137s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.024s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:52: DeprecationWarning: Class RandomizedPCA is deprecated; RandomizedPCA was deprecated in 0.18 and will be removed in 0.20. Use PCA(svd_solver='randomized') instead. The new implementation DOES NOT store whiten ``components_``. Apply transform to get them.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled \n",
    "# dataset) : unsupervised feature extraction / dimentionality reduction\n",
    "n_components =  150\n",
    "\n",
    "#print \"extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0])\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print \"Projecting the input data on the eigenfaces orthonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_Test)\n",
    "\n",
    "print \"done in %0.3fs\" %(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the classifier to the trainning set\n",
      "done in 13.313s\n",
      "Best estimator found by grid search: \n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.005, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#Train a SVM classification model\n",
    "\n",
    "print \"fitting the classifier to the trainning set\"\n",
    "t0 = time()\n",
    "param_grid={\n",
    "    'C':[1e3,5e3,1e4,5e4,1e5],\n",
    "    'gamma':[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "}\n",
    "# for sklearn version 0.16 or prior, the class_weight parameter is 'auto'\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid) #to check if is going wrong\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "print \"Best estimator found by grid search: \"\n",
    "print clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quantitave evaluation of the model quality on the test set\n",
    "\n",
    "print \"predicting the people names on the testing set\"\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "print classification_report(y_test, y_pred, target_names = target_names)\n",
    "print confusion_matrix(y_test, y_pred, labels=range(n_Classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Qualitative evaluation  of the predictions using matplotlib\n",
    "\n",
    "def plot_gallery(images, titles, h, w,  n_row=3, n_col=4):\n",
    "    \"\"\"\n",
    "    helper function to plot a gallery of portraits\n",
    "    \"\"\"\n",
    "    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    pl.subplots_adjust(bottom=0, left=0.1, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        pl.subplot(n_row, n_col, i + 1)\n",
    "        pl.imshow(images[i].reshape((h, w)), cmap = pl.cm.gray)\n",
    "        pl.title(titles[i], size=12)\n",
    "        pl.xticks(())\n",
    "        pl.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the result of( the prediction on a portion of the test set\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                        for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_Test, prediction_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the gallery of the most significative eigenfaces\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the Variance of Each PC\n",
    "# how much of the variance is explained by the first principal component?\n",
    "arrvar = pca.explained_variance_ratio_ # : array, shape (n_components,)\n",
    "arrvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
